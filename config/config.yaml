# Copyright (c) 2025 Beijing Volcano Engine Technology Co., Ltd.
# SPDX-License-Identifier: Apache-2.0
#
# OpenContext Configuration File

# General switch
enabled: true

# Logging configuration
logging:
  level: DEBUG # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
  log_path: "${CONTEXT_PATH:.}/logs/opencontext.log" # Log file path

user_setting_path: "${CONTEXT_PATH:.}/config/user_setting.yaml"

# Service mode configuration (for containerized deployment)
service_mode:
  enabled: true  # Enable stateless service mode
  require_redis: true  # Redis is required in service mode
  require_external_storage: true  # External storage (MySQL/DashVector) is required

# 文档处理配置
document_processing:
  enabled: true
  batch_size: 3        # Number of images processed by VLM at once (recommended 2-5)
  max_image_size: 1024 # Maximum image size (pixels), larger sizes increase accuracy but also API costs
  dpi: 200             # DPI for converting PDF to images (recommended 150-300)

  # Page-by-page detection configuration (to optimize VLM usage)
  text_threshold_per_page: 50 # Scanned document threshold: pages with fewer characters than this value are considered scanned documents (requires VLM)

# config/config.yaml

llm:
  enabled: true
  provider: "openai"  # MineContext uses 'openai' client for Volcengine/Doubao too
  config:
    # ⚠️ MUST FILL IN YOUR KEY HERE
    api_key: "${LLM_API_KEY}" 
    base_url: "${LLM_BASE_URL:https://ark.cn-beijing.volces.com/api/v3}"
    model: "${LLM_MODEL:doubao-seed-1-6-251015}" 
    temperature: 0.1
    max_tokens: 4096

vlm_model:
  base_url: "${VLM_BASE_URL:https://ark.cn-beijing.volces.com/api/v3}"
  api_key: "${VLM_API_KEY}"
  model: "${VLM_MODEL:doubao-seed-1-6-251015}"
  provider: "openai"

embedding_model:
  base_url: "${EMBEDDING_BASE_URL:https://ark.cn-beijing.volces.com/api/v3}"
  api_key: "${EMBEDDING_API_KEY}"
  model: "${EMBEDDING_MODEL:doubao-embedding-large-text-240915}"
  provider: "openai"
  output_dim: 2048

# Context capture module
capture:
  enabled: "${CAPTURE_ENABLED:true}"
  # Screenshot capture
  screenshot:
    enabled: "${SCREENSHOT_CAPTURE_ENABLED:false}"
    capture_interval: 5 # Screenshot interval (seconds)
    storage_path: "${CONTEXT_PATH:.}/screenshots" # Screenshot save directory
  text_chat:
    enabled: "${TEXT_CHAT_CAPTURE_ENABLED:true}"
    buffer_size: 10

  # Folder monitoring
  folder_monitor:
    enabled: false
    monitor_interval: 30 # Monitor interval (seconds)
    watch_folder_paths:
      - "${CONTEXT_PATH:.}/persist/Documents"

    recursive: true
    max_file_size: 104857600 # Maximum file size to process (bytes), default: 100MB
    initial_scan: true

  # File monitoring
  file_monitor:
    enabled: false
    recursive: true
    initial_scan: true
    monitor_paths: "./doc"
    capture_interval: 30 # File monitoring interval (seconds)
    ignore_patterns:
      - "**/node_modules/**"
      - "**/.git/**"

  # Vaults document monitoring
  vault_document_monitor:
    enabled: false
    monitor_interval: 30 # Monitoring interval (seconds)
    initial_scan: true # Whether to perform an initial scan

# Context processing module
processing:
  enabled: "${PROCESSING_ENABLED:true}"
  # Document processor configuration
  text_chat_processor:
    enabled: "${TEXT_CHAT_PROCESSOR_ENABLED:true}"
  document_processor:
    enabled: "${DOCUMENT_PROCESSOR_ENABLED:false}"
    batch_size: 5
    batch_timeout: 30
  screenshot_processor:
    enabled: "${SCREENSHOT_PROCESSOR_ENABLED:false}"
    dedup_cache_size: 30
    similarity_hash_threshold: 7
    batch_size: 20 # Increase batch size to improve throughput
    batch_timeout: 10 # Reduce timeout to improve response speed
    max_image_size: 1920 # Limit image size to reduce memory usage
    resize_quality: 85 # Balance quality and performance
    enabled_delete: true
    max_raw_properties: 5

  # Context merger configuration
  context_merger:
    enabled: "${CONTEXT_MERGER_ENABLED:true}"
    # Basic configuration
    # similarity_threshold: 0.90
    # associative_similarity_threshold: 0.6
    similarity_threshold: 0.01
    associative_similarity_threshold: 0.01

    # Intelligent merging configuration
    use_intelligent_merging: false # Enable intelligent strategy merging
    enable_memory_management: true # Enable memory management
    cleanup_interval_hours: 24 # Cleanup check interval

    # Cross-type association configuration
    enable_cross_type_processing: true # Enable cross-type processing
    conversion_confidence_threshold: 0.8 # Conversion confidence threshold
    max_conversions_per_session: 10 # Maximum conversions per session

    # Type-specific configuration
    # Profile type configuration
    ENTITY_CONTEXT_similarity_threshold: 0.85
    ENTITY_CONTEXT_retention_days: 365
    ENTITY_CONTEXT_max_merge_count: 5

redis:
  enabled: true
  host: "${REDIS_HOST:localhost}"
  port: ${REDIS_PORT:6379}
  password: "${REDIS_PASSWORD:}"
  db: ${REDIS_DB:0}
  key_prefix: "opencontext:"
  # Connection pool settings
  max_connections: 10
  socket_timeout: 5.0
  socket_connect_timeout: 5.0
  retry_on_timeout: true

# User Memory Cache
memory_cache:
  snapshot_ttl: 300           # Snapshot cache TTL in seconds (default: 5 min)
  recent_days: 7              # Recent memories time window in days (default: 7)
  max_recently_accessed: 50   # Max items tracked in accessed hash
  max_today_events: 30        # Max today L0 events in cache
  max_recent_documents: 10    # Max recent documents in cache
  max_recent_knowledge: 10    # Max recent knowledge in cache
  accessed_ttl: 604800        # Accessed tracking hash TTL in seconds (default: 7 days)
  max_entities: 20            # Max entities in cache response

# Context storage module
storage:
  enabled: true
  backends:
    # Vector database configuration - Choose either ChromaDB or Qdrant
    # ChromaDB (default)
    # - name: "default_vector"
    #   storage_type: "vector_db"
    #   backend: "chromadb"
    #   config:
    #     mode: "local" # Options: "local", "server"
    #     path: "${CONTEXT_PATH:.}/persist/chromadb"
    #     collection_prefix: "opencontext"

    # VikingDB database configuration
    - name: "default_vector"
      storage_type: "vector_db" 
      backend: "vikingdb"
      default: true
      config:
        access_key_id: "${VIKINGDB_ACCESS_KEY_ID}"
        secret_access_key: "${VIKINGDB_SECRET_ACCESS_KEY}"
        region: "${VIKINGDB_REGION:cn-beijing}"
        dimension: 2048
        max_connections: 100           # 最大连接数
        max_connections_per_host: 20   # 每主机最大连接数
        collection_name: "opencontext"  # 可选，默认 opencontext
        index_name: "opencontext_index"  # 可选，默认 opencontext_index

    # Qdrant (alternative vector database)
    # Uncomment to use Qdrant instead of ChromaDB:
    # - name: "default_vector"
    #   storage_type: "vector_db"
    #   backend: "qdrant"
    #   config:
    #     # Vector size MUST match your embedding model's output dimension
    #     vector_size: 1536 # Set this to match embedding_model.output_dim above (line 37)
    #
    #     # Local mode (uses file-based storage):
    #     path: "${CONTEXT_PATH:.}/persist/qdrant"
    #
    #     # Server mode (comment out 'path' above and uncomment the settings below):
    #     # host: "localhost"
    #     # port: 6333
    #     # https: false
    #     # api_key: "${QDRANT_API_KEY}"  # Optional: API key for authentication

    - name: "document_store"
      storage_type: "document_db"
      backend: "mysql"
      default: true
      config:
        host: "${MYSQL_HOST:localhost}"
        port: 3306
        user: "${MYSQL_USER:root}"
        password: "${MYSQL_PASSWORD:root123}"
        database: "${MYSQL_DATABASE:opencontext}"
        charset: "utf8mb4"

    # - name: "document_store"
    #   storage_type: "document_db"
    #   backend: "sqlite"
    #   config:
    #     path: "${CONTEXT_PATH:.}/persist/sqlite/app.db"

# Context consumption module
# Set to false to disable all consumption components (tips, todos, activity, report)
# This also prevents creation of todo collection in vector databases
# 服务器模式下不应该开启消费组件。
consumption:
  enabled: "${CONSUMPTION_ENABLED:false}"

# web server
web:
  host: "0.0.0.0"
  port: 1733
  enabled: "${WEB_ENABLED:true}"

# API authentication configuration
api_auth:
  enabled: false # Enable authentication in production environment for security
  api_keys:
    - "${CONTEXT_API_KEY:test}"
  excluded_paths:
    - "/health"
    - "/api/health"
    - "/api/auth/status"
    - "/"
    - "/static/*"
    - "/contexts"
    - "/vector_search"
    - "/debug"
    - "/chat"
    - "/advanced_chat"
    - "/monitoring"
    - "/assistant"
    - "/vaults"

# Prompts configuration
prompts:
  language: "zh"

tools:
  # Operation tools configuration
  operation_tools:
    web_search_tool:
      enabled: true
      web_search:
        engine: duckduckgo
        max_results: 5
        timeout: 10

# Task scheduler configuration (for periodic tasks)
scheduler:
  enabled: "${SCHEDULER_ENABLED:true}"
  
  # User key configuration (determines how user tasks are identified)
  user_key_config:
    use_user_id: true      # Always true (required)
    use_device_id: true    # Set to false to ignore device_id
    use_agent_id: true     # Set to false to switch to 2-key mode (user_id:device_id)
    default_device_id: "default"
    default_agent_id: "default"
  
  # Executor configuration
  executor:
    check_interval: 10     # How often to check for due tasks (seconds)
    max_concurrent: ${SCHEDULER_EXECUTOR_MAX_CONCURRENT:5}
    lock_timeout: 300      # Distributed lock timeout (seconds)
  
  # Task definitions
  tasks:
    # Memory compression task (triggered by user activity)
    memory_compression:
      enabled: "${MEMORY_COMPRESSION_TASK_ENABLED:true}"
      trigger_mode: "user_activity"  # Options: user_activity, periodic
      # interval: 1800        # Delay after user activity (seconds)
      interval: 30        # Delay after user activity (seconds)
      task_ttl: 7200        # Task state TTL (seconds)
    
    # Data cleanup task (periodic)
    data_cleanup:
      enabled: false
      trigger_mode: "periodic"
      # interval: 86400       # Run every 24 hours
      interval: 60       # Run every 5 minutes
      retention_days: 30    # Keep data for 30 days

    # Hierarchy summary task (generates daily/weekly/monthly event summaries)
    # Triggered by user activity (data push), runs at most once per 24h per user
    hierarchy_summary:
      enabled: "${HIERARCHY_SUMMARY_ENABLED:true}"
      trigger_mode: "user_activity"
      interval: 86400         # 24h delay after user push, then generate summaries
      timeout: 600            # 10 min timeout for LLM calls
      task_ttl: 172800        # 48h TTL for task pickup window

# Intelligent completion service configuration
completion:
  enabled: false
